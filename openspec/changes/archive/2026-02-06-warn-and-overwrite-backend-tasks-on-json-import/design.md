## Context

既存の `data-import` 仕様では、JSON インポート時の確認とローカル置換は定義されているが、ログイン済みユーザーのバックエンドデータをどう扱うかが曖昧である。現在の同期仕様（`task-sync`）では、状況によりバックエンド/ローカルのどちらかを優先して上書きするため、インポート直後に再同期や再ログインが発生すると、ユーザーが意図したインポート結果が失われるリスクがある。

この変更では、インポートを「ユーザーが明示的に選んだ真実のソース」として扱い、警告承認後にローカルとバックエンドを同じデータセットへ収束させる。

## Goals / Non-Goals

**Goals:**
- インポート前に破壊的操作であることを明確に警告し、ユーザー同意なしでは実行しない。
- インポート承認後、ローカルタスクを JSON 内容で置換する。
- ログイン済み時はバックエンドの当該ユーザータスクもインポート内容で全件上書きする。
- 上書き失敗時の扱いを定義し、サイレントな不整合を避ける。

**Non-Goals:**
- 新しいファイル形式（CSV 等）の追加。
- 既存タスクとインポートデータのマージ戦略導入。
- バージョン管理や差分適用 UI の追加。

## Decisions

### 1. インポート実行前の確認を必須化する
- 決定: JSON 解析・検証後、実反映前に確認ダイアログを表示し、承認時のみ処理を進める。
- 理由: 誤操作での全消去を防ぎ、ユーザーの意図を明示的に取得できる。
- 代替案:
  - ダイアログなしで即時反映: 操作性は高いが、破壊的変更として安全性が不足。
  - 設定画面で事前同意フラグ: 文脈上の確認が弱く、意図しない実行を防ぎにくい。

### 2. 上書き方式は「全削除後にインポートデータ再作成」を基本とする
- 決定: ログイン済み時、バックエンドに対して既存タスクを全削除し、インポートデータを親子関係を保って再作成する。
- 理由: 既存 API（`DELETE /tasks/{id}`、`POST /tasks`）で実現でき、仕様の一貫性が高い。ID 再採番を許容すれば実装が単純で、最終状態を明確に定義できる。
- 代替案:
  - 専用の一括置換 API を新設: 一貫性制御はしやすいが、バックエンド改修範囲が増える。
  - 既存データとの差分更新: API 呼び出しは減る可能性があるが、複雑で不整合リスクが高い。

### 3. 同期の最終成功条件を「バックエンド再取得での一致確認」とする
- 決定: 上書き処理後に `GET /tasks` を再実行し、取得結果で local state を確定する。
- 理由: サーバー側正規化や生成 ID を含む最終状態を単一ソースで確定できる。
- 代替案:
  - クライアント側で成功レスポンスのみから確定: API の揺らぎや欠落時に最終一致を保証しづらい。

### 4. 失敗時は「ローカルの新データを維持しつつ、同期失敗を明示」する
- 決定: バックエンド上書き途中で失敗した場合、ローカルはインポート済み状態を維持し、再同期を促すエラーを表示する。
- 理由: ユーザーが選んだインポート結果を直ちに失わせず、再試行導線を提供できる。
- 代替案:
  - ローカルを旧状態へロールバック: 実装が複雑で、復元失敗時の挙動が不明瞭。
  - 失敗時にサイレント無視: 不整合に気づけずデータ喪失の温床になる。

## Risks / Trade-offs

- [大量タスク時に API 呼び出しが増える] → 親子順バッチ化と進捗表示、必要に応じた並列度制御で緩和する。
- [削除完了後に再作成が失敗するとバックエンドが空に近づく] → 失敗通知を必須化し、再試行導線とログ出力を用意する。
- [ID 再生成により外部参照が切れる可能性] → 本機能の仕様として ID 維持を保証しないことを明記し、依存箇所を洗い出す。
- [ローカル成功・バックエンド失敗の一時的不整合] → UI 上で同期失敗状態を明示し、次回同期で収束させる。
